{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13818/3764464123.py:12: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n",
      "2024-12-05 10:46:45.144556: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 10:46:45.171426: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 10:46:45.654849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "from IPython.display import Markdown, display\n",
    "import importlib\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "import colorsys\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import xgboost as xgb\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import src.cropnet as cropnet\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "import tensorflow as tf\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/full_data/processed/processed_merged.feather\"\n",
    "df = pd.read_feather(path)\n",
    "f = open(path.replace(\".feather\", \".json\"), \"r\")\n",
    "correlation_filters = json.load(f)\n",
    "f.close()\n",
    "if 'level_0' in df.columns:\n",
    "    df = df.drop(columns=['level_0'])\n",
    "df = df.reset_index()\n",
    "if 'level_0' in df.columns:\n",
    "    df = df.drop(columns=['level_0'])\n",
    "\n",
    "df = df[np.isnan(df['yield']) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'yield_1'\n",
    "predictors = [c for c in correlation_filters['base'] if c not in ['index', 'x', 'y', 'x_int', 'y_int', 'polygon_id', 'grdkod_mar'] and \"yield\" not in c and \"_pid\" not in c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mX = np.mean(df[predictors], axis=0)\n",
    "sX = np.std(df[predictors], axis=0)\n",
    "sX[sX == 0] = 1\n",
    "\n",
    "mY = np.mean(df[target], axis=0)\n",
    "sY = np.std(df[target], axis=0)\n",
    "\n",
    "norm_info = {\n",
    "    'X': {'mean': mX, 'std': sX},\n",
    "    'y': {'mean': mY, 'std': sY}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:06<00:00, 23.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = []\n",
    "for pid in tqdm(set( df['matching_pid'])):\n",
    "    pdf = df[df['matching_pid'] == pid]\n",
    "    X = ((pdf.loc[df['matching_pid'] == pid, predictors]-mX)/sX).values\n",
    "    y = ((pdf.loc[df['matching_pid'] == pid, target]-mY)/sY).values.reshape((-1, 1))\n",
    "    info = {\n",
    "        'x': pdf.x.values,\n",
    "        'y': pdf.y.values,\n",
    "        'pid': pid\n",
    "    }\n",
    "    dataset.append((X, y, info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, p_val, p_test, seed=-1):\n",
    "    \n",
    "    N = np.sum([X.shape[0] for X, y, info in dataset])\n",
    "    rem = [data for data in dataset]\n",
    "    \n",
    "    data_val = []\n",
    "    val_size = 0\n",
    "    while val_size/N < p_val:\n",
    "        idx = random.choice(range(len(rem)))\n",
    "        data = rem.pop(idx)\n",
    "        data_val.append(data)\n",
    "        val_size += data[0].shape[0]\n",
    "        \n",
    "        \n",
    "    data_test = []\n",
    "    test_size = 0\n",
    "    while test_size/N < p_test:\n",
    "        idx = random.choice(range(len(rem)))\n",
    "        data = rem.pop(idx)\n",
    "        data_test.append(data)\n",
    "        test_size += data[0].shape[0]\n",
    "        \n",
    "    return rem, data_val, data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "model_list = [\n",
    "\t#LinearRegression(),\n",
    "\t#SVR(),\n",
    "\t#Ridge(),\n",
    "\t#Lasso(),\n",
    "\t#BaggingRegressor(),\n",
    "\t#AdaBoostRegressor(),\n",
    "\t#KNeighborsRegressor(),\n",
    "\t#GradientBoostingRegressor(),\n",
    "\t#SGDRegressor(random_state=0),\n",
    "\txgb.XGBRegressor(random_state=0),\n",
    "\t#ExtraTreesRegressor(random_state=0),\n",
    "\t#DecisionTreeRegressor(random_state=0),\n",
    "\t#RandomForestRegressor(random_state=0),\n",
    "    #MLPRegressor(hidden_layer_sizes=(512,128, 64,32,16,4),random_state=0,max_iter=20)\n",
    "]\n",
    "\n",
    "for model in model_list:\n",
    "\n",
    "    print(\"\")\n",
    "    print(str(model).split(\"(\")[0] + \"()\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_p = model.predict(X_val)\n",
    "\n",
    "    err = y_val - y_p\n",
    "    print(\"MSE:\", np.mean(err**2))\n",
    "    print(\"R2:\", sklearn.metrics.r2_score(y_val, y_p))\n",
    "    print(\"adj_R2:\", 1 - (1-model.score(X_val, y_val))*(len(y_val)-1)/(len(y_val)-X_val.shape[1]-1))\n",
    "    print(\"CV:\", np.std(y_val, ddof=1) / np.mean(y_val))\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9395790581226872, 0.7311865930396815, 0.09616125279623527, 0.7903349157417794] [0.7933992415003819, 0.8276775394888918, 0.07998416961914041, 0.8504993716303069]\n",
      "[1.3204075532112147, 0.6390156207511255, 0.12033915457064907, 0.5175783069149744] [0.9350589006909552, 0.7679245853098469, 0.09853498699810839, 0.7580705346545531]\n",
      "[1.2678699512605494, 0.6776459112339457, 0.1240359732310901, 0.7202425726092636] [0.8580925747328405, 0.7886034791090879, 0.09514198385661442, 0.8718553452680184]\n",
      "[1.0610103204624588, 0.7442947484190267, 0.12192259548334726, 0.7713260907104742] [0.8812253823639268, 0.8071940351614938, 0.10582137927013092, 0.8422565280770424]\n",
      "[1.1148143524518725, 0.7010895922920237, 0.11201234589114949, 0.8233369191967976] [0.899938577931958, 0.8019172944485757, 0.09356241634462621, 0.8848758502772173]\n",
      "[1.026604980161377, 0.7432297339639814, 0.10272723691506362, 0.7670937537740425] [0.8937529014797954, 0.7868429298279643, 0.08985662396363166, 0.8234737352236265]\n",
      "[0.9661735346528653, 0.7352772283544949, 0.10350286631977, 0.7729083030207123] [0.8055662418683665, 0.8211733554520513, 0.08598493016166366, 0.8421322213647467]\n",
      "[0.931643632490915, 0.7744264529318233, 0.09000343954357475, 0.7820098213094265] [0.7597002225716396, 0.8573514618554694, 0.0753491952715813, 0.8550488068379121]\n",
      "[0.9682796766315516, 0.7771885453210411, 0.1189958270753446, 0.8585254964509503] [0.8009544913934102, 0.83721954801338, 0.0929748305574807, 0.9031962396643269]\n",
      "[1.0234920135813057, 0.7217151246289855, 0.10254024766486138, 0.7743940076062297] [0.9172938126827854, 0.7802795774423132, 0.09051771964794351, 0.8187831225452327]\n",
      "[1.06198751 0.72450696 0.10922409 0.75777502]\n",
      "[0.85449823 0.80761838 0.09077282 0.84501918]\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for i in range(10):\n",
    "    data_train, data_val, data_test = split_data(dataset, 0.15, 0.15)\n",
    "\n",
    "    Xt = np.concatenate([data[0] for data in data_train])\n",
    "    yt = np.concatenate([data[1] for data in data_train])\n",
    "\n",
    "    model = xgb.XGBRegressor(random_state=0)\n",
    "    model.fit(Xt, yt);\n",
    "\n",
    "    y_tot = np.zeros(0)\n",
    "    y_pred = np.zeros(0)\n",
    "    test_err = np.zeros(0)\n",
    "    test_err_norm = np.zeros(0)\n",
    "    pids = np.zeros(0)\n",
    "    for X, y, info in data_test:\n",
    "        pred = model.predict(X)\n",
    "        \n",
    "        yp = pred.reshape(-1)\n",
    "        yt = y.reshape(-1)\n",
    "        err = (yt - yp)*norm_info['y']['std']\n",
    "        \n",
    "        y_tot = np.concatenate([y_tot, yt])\n",
    "        y_pred = np.concatenate([y_pred, yp])\n",
    "        test_err = np.concatenate([test_err, err])\n",
    "        test_err_norm = np.concatenate([test_err_norm, err - np.nanmean(err)])\n",
    "        pids = np.concatenate([pids, np.ones(err.shape)*info['pid']])\n",
    "        \n",
    "    y_tot = y_tot*norm_info['y']['std'] + norm_info['y']['mean']\n",
    "    scores_unnorm = [np.sqrt(np.nanmean(test_err**2)), np.nanmean((np.abs(test_err) < 1)[np.isnan(test_err) == False]), np.nanmean(np.abs(test_err/y_tot)), 1-np.sum(test_err**2)/np.sum((y_tot-np.mean(y_tot))**2)]\n",
    "    scores_norm = [np.sqrt(np.nanmean(test_err_norm**2)), np.nanmean((np.abs(test_err_norm) < 1)[np.isnan(test_err_norm) == False]), np.nanmean(np.abs(test_err_norm/y_tot)), 1-np.sum(test_err_norm**2)/np.sum((y_tot-np.mean(y_tot))**2)]\n",
    "    result = [scores_unnorm, scores_norm, [list(y_tot), list(y_pred), list(test_err), list(test_err_norm), list(pids)]]\n",
    "    score_list.append(result)\n",
    "    print(scores_unnorm, scores_norm)\n",
    "    \n",
    "cropnet.save_score_to_json(score_list, \"results_final/other_models/xgboost.json\")\n",
    "\n",
    "\n",
    "with open('results_final/other_models/xgboost.json', 'r') as f:\n",
    "    scores_read = json.load(f)\n",
    "    print(np.mean(np.array([s[0] for s in scores_read]), axis=0))\n",
    "    print(np.mean(np.array([s[1] for s in scores_read]), axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
